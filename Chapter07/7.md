### JMX set up for external IPs
```
LOCAL_JMX='no'

if [ "$LOCAL_JMX" = "yes" ]; then
 JVM_OPTS="$JVM_OPTS -Dcassandra.jmx.local.port=$JMX_PORT -XX:+DisableExplicitGC"
else
 JVM_OPTS="$JVM_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT"
 JVM_OPTS="$JVM_OPTS -Dcom.sun.management.jmxremote.rmi.port=$JMX_PORT"
 JVM_OPTS="$JVM_OPTS -Djava.rmi.server.hostname=127.0.0.1"
 JVM_OPTS="$JVM_OPTS -Dcom.sun.management.jmxremote.ssl=false"
 JVM_OPTS="$JVM_OPTS -Dcom.sun.management.jmxremote.authenticate=false"
fi
```

### JMXTerm
```
java -jar <absolutePath>/jmxterm-1.0.0.-uber.jar
open <IP>:7199
domains
get -b org.apache.cassandra.net:type=FailureDetector DownEndpointCount
run -b org.apache.cassandra.db:type=StorageService stopGossiping

echo -e "open <IP>:7199\nrun -b org.apache.cassandra.db:type=StorageService forceTerminateAllRepairSessions\nclose" > jmxcommands
java -jar<absolutePath>/jmxterm-1.0.0.-uber.jar -v silent -n < jmxcommands
```

### nodetool
If CASSANDRA_HOME is set then can use directly `nodetool` other wise `$CASSANDRA_HOME/bin/nodetool`
```
nodetool describecluster
nodetool gcstats
nodetool getcompactionthreshold system_auth roles
nodetool getcompactionthroughput
nodetool getconcurrentcompactors
nodetool getendpoints system_auth roles cassandra
nodetool getlogginglevels
nodetool getstreamthroughput
nodetool gettimeout read
nodetool gossipinfo
nodetool info
nodetool netstats
nodetool proxyhistograms
nodetool status
nodetool tablestats system_auth.roles
nodetool tpstats
nodetool verify system_auth roles
nodetool cleanup
nodetool drain
nodetool flush
nodetool resetlocalschema
nodetool stopdaemon
nodetool truncatehints
nodetool upgradesstables
```

### Telegraf
```
rpm -ivh https://dl.influxdata.com/telegraf/releases/telegraf-1.7.4-1.x86_64.rpm
# telegraf.conf
[global_tags]
  env = "sandbox"
  app = "mastering apache cassandra"
  region = "central"
  ip = "127.0.0.1"

[agent]
  interval = "10s"
  round_interval = true
  metric_buffer_limit = 1000
  flush_buffer_when_full = true
  collection_jitter = "0s"
  flush_interval = "60s"
  flush_jitter = "0s"
  debug = false
  quiet = false
  hostname = ""
  omit_hostname = false

[[outputs.influxdb]]
  urls = ["http://127.0.0.1:8086"]
  database = "telegraf"

# # optional
# [[outputs.kafka]]
# brokers = ["<broker>:9092"]
# topic = "<topicname>"
# compression_codec = 0
# required_acks = 0
# max_retry = 3
# data_format = "influx"

[[inputs.http_listener]]
  service_address = "127.0.0.1:5100"
  read_timeout = "10s"
  write_timeout = "10s"

[[inputs.net]]
# start telegraf service
service telegraf start
```

### JMXTrans
```
rpm -ivh http://central.maven.org/maven2/org/jmxtrans/jmxtrans/270/jmxtrans-270.rpm
# jmxtrans.yaml
servers:
  - port: 7199
    host: 127.0.0.1
    queries:
      - outputWriters:
          - "@class": com.googlecode.jmxtrans.model.output.InfluxDbWriterFactory
            url: "http://127.0.0.1:5100/"
            username: admin
            password: admin
            database: jmxDB
        obj: org.apache.cassandra.net:type=FailureDetector
        attr:
          - DownEndpointCount
        resultAlias: FailureDetector
# start jmxtrans service
service jmxtrans start
```

### InfluxDB
```
rpm -ivh https://dl.influxdata.com/influxdb/releases/influxdb-1.6.2.x86_64.rpm
systemctl start influxd
# initialize CLI and connect to local InfluxDB
influx
# create database telegraf
create database telegraf
# show list of databases
show databases
# use telegraf database
use telegraf
# show list of measurements
show measurements
# show series from cpu
show series from cpu
```

### Grafana
```
rpm -ivh https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-5.2.4-1.x86_64.rpm
# start grafana service
service grafana-server start

# datasource creation
cat > /tmp/grafanaDataSource.json <<EOF
{
  "id": 1,
  "orgId": 1,
  "name": "MasteringApacheCassandra",
  "type": "influxdb",
  "typeLogoUrl": "public/app/plugins/datasource/influxdb/img/influxdb_logo.svg",
  "access": "proxy",
  "url": "http://127.0.0.1:8086",
  "password": "",
  "user": "",
  "database": "telegraf",
  "basicAuth": false,
  "isDefault": true,
  "jsonData": {
    "keepCookies": []
  },
  "readOnly": false
}
EOF

# As username and password are not changed
curl -X "POST" "http://localhost:3000/api/datasources" -H "Content-Type: application/json" --user admin:admin --data-binary @/tmp/grafanaDataSource.json

# dashboard creation
cat > /tmp/grafanaDashboard.json <<EOF
{
  "dashboard": {
    "id": null,
    "uid": null,
    "title": "Production Overview",
    "tags": [ "templated" ],
    "timezone": "browser",
    "schemaVersion": 16,
    "version": 0
  },
  "folderId": 0,
  "overwrite": false
}
EOF

curl -X "POST" -i "http://localhost:3000/api/dashboards/db" -H "Content-Type: application/json" --user admin:admin --data-binary @/tmp/grafanaDashboard.json
```

### logging
```
# logback.xml extra parameters
  <logger name="org.apache.cassandra.service.StorageService" level="WARN"/>
  <logger name="org.apache.cassandra.streaming.StreamResultFuture" level="WARN"/>
  <logger name="org.apache.cassandra.repair" level="WARN"/>
</configuration>

# GC logs
# Setting Log Dir
CASSANDRA_LOG_DIR=/usr/lib/cassandra/logs
JVM_OPTS="$JVM_OPTS -Dcassandra.logdir=${CASSANDRA_LOG_DIR}"

# GC logging options
JVM_OPTS="$JVM_OPTS -XX:+PrintGCDetails"
JVM_OPTS="$JVM_OPTS -XX:+PrintGCDateStamps"
JVM_OPTS="$JVM_OPTS -XX:+PrintHeapAtGC"
JVM_OPTS="$JVM_OPTS -XX:+PrintTenuringDistribution"
JVM_OPTS="$JVM_OPTS -XX:+PrintGCApplicationStoppedTime"
JVM_OPTS="$JVM_OPTS -XX:+PrintPromotionFailure"
JVM_OPTS="$JVM_OPTS -XX:PrintFLSStatistics=1"

JVM_OPTS="$JVM_OPTS -Xloggc:${CASSANDRA_LOG_DIR}/gc.log"
JVM_OPTS="$JVM_OPTS -XX:+UseGCLogFileRotation"
JVM_OPTS="$JVM_OPTS -XX:NumberOfGCLogFiles=10"
JVM_OPTS="$JVM_OPTS -XX:GCLogFileSize=10M"
```

### Filebeat
```
rpm -ivh https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.4.1-x86_64.rpm
# filebeat.yml
filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /usr/lib/cassandra/logs/*.log
  multiline.pattern: '^[[:space:]]'
  multiline.negate: false
  multiline.match: after

# start filebeat service
service filebeat start
```

### ElasticSearch
```
rpm -ivh https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.4.1.rpm
# elasticsearch.yml
cluster.name: <applicationName>
node.name: <hostname>
node.attr.rack: <rack/az>
path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch
network.host: 127.0.0.1
http.port: 9200

# start elasticsearch service
service elasticsearch start
```

### Kibana
```
rpm -ivh https://artifacts.elastic.co/downloads/kibana/kibana-6.4.1-x86_64.rpm
# kibana.yml
server.port: 5601
server.host: "127.0.0.1"
elasticsearch.url: "http://127.0.0.1:9200"
# If authentication is enabled on elasticsearch cluster
#elasticsearch.username: "user"
#elasticsearch.password: "pass"

# start kibana service
service kibana start
```

### All in one Docker
```
# Pull from dockerhub
docker pull malepati/cassandra-spark-jupyter:latest

# Build from source
# Clone git repo https://github.com/malepati/book
git clone git@github.com:malepati/book.git
cd book/MasteringApacheCassandra3rdEdition/docker
docker build -t malepati/cassandra-spark-jupyter:latest cassandra-spark-jupyter/.

# Running docker container locally
docker run \
--name demo \
--hostname 'csapp1-0' \
-p 3000:3000 \
-p 7199:7199 \
-p 8086:8086 \
-p 9042:9042 \
-e 'MONITOR=true' \
-e 'SPARK=false' \
--rm -it malepati/cassandra-spark-jupyter:latest
```
